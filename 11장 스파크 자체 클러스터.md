# 11장 스파크 자체 클러스터

스파크 자체 클러스터는 스파크에 맞게 최적화되어 간단하고 빠르다. 



## 11.1 스파크 자체 클러스터의 컴포넌트

스파크 자체 클러스터는 마스터프로세스와 워커프로세스(슬레이브) 로 구성된다. 

마스터 프로세스는 10장의 클러스터 매니저 역할을 한다. 

마스터는 클라이언트가 실행을 요청한 애플리케이션들을 받고 각 애플리케이션의 워커 리소스를 스케줄링한다.

워커는 애플리케이션의 태스크를 처리할 실행자를 시작한다(클러스터 배포모드에서는 애플리케이션의 드라이버를 싱행하는 역할도 담당.)

드라이버는 스파크 잡을 조정하고 모니터링하는 컴포넌트, 실행자는 잡의 태스크를 실행하는 컴포넌트.



스파크 자체 클러스터를 구성하려면 클러스터의 모든 노드가 워커의 역할을 하도록 각 노드에 스파크를 설치해야함.

빌드하는방법(https://spark.apache.org/docs/latest/building-spark.html) 참고



노드 2개로 구성된 스파크 자체 클러스터. 

이 클러스터는 마스터 프로세스하나와 워커 프로세스 두개를 실행. 

![image-20211226162647599](C:\Users\ahdbs\AppData\Roaming\Typora\typora-user-images\image-20211226162647599.png)순서

1. 클라이언트 프로세스는 애플리케이션을 마스터에 제출.

2. 마스터는 1번 노드의 워커에 드라이버를 시작하라고 지시.

3. 1번 노드의 워커는 드라이버 JVM을 시작.

4. 마스터는 두 워커에 애플리케이션의 실행자를 시작하라고 지시.

5. 두워커는 각각 실행자 JVM을 시작.

6. 드라이버는 실행자와 직접 통신하며 스파크 애플리케이션을 실행.

   클러스터의 프로세스들은 더이상 관여X

이는 스파크 드라이버를 클러스터 내부에서 실행하는 모드 -> 클러스터 배포모드



## 11.2 스파크 자체 클러스터 시작

10장의 로컬 클러스터는 애플리케이션과 스파크를 동시 시작. 반면 스파크 자체 클러스터에는 애플리케이션을 제출하거나 스파크 셸을 시작하기 전에 클러스터를 미리 가동해야 한다. 

클러스터가 정상 가동되면 마스터 접속 URL을 통해 애플리케이션을 클러스터와 연결할 수 있다. 

``` spark://master_hostname:port
spark://master_hostname:port
```

예비 마스터 프로세스를 사용할땐 마스터주소를 여러개 지정할 수 있다.

```
spark://master1_hostname:port1, master2_hostname:port2
```

스파크 자체 클러스터를 시작하려면 스파크가 제공하는 스크립트를 사용하거나 각 컴포넌트를 수동으로 시작해야 한다.

 

### 11.2.1 셸스크립트로 클러스터 시작

스파크 자체 클러스터를 시작하는 가장 쉬운 방법.

스파크가 제공하는 시작 스크립트를 실행하는것. 

스파크는 자체 클러스터의 컴포넌트를 시작하는 세가지 시작 스크립트를 제공.

- `start-master.sh` 마스터 프로세스를 시작한다.
- `start-slaves.sh` 클러스터에 등록된 워커 프로세스들을 모두 시작한다.
- `start-all.sh` 마스터 프로세스와 워커 프로세스들을 시작한다.
- `stop-master.sh, stop-slaves.sh, stop-all.sh` 각 컴포넌트를 중지하는 종료스크립트.



### 11.2.2 수동으로 클러스터 시작.

스파크는 클러스터 컴포넌트를 수동으로 시작하는 방법도 제공. 

`spark-class org.apache.spark.deploy.master.Master`

`spark-class org.apache.spark.deploy.worker.Worker spark://<IPADDR>:<PORT>`

또 spark-class스크립트에 여러 매개변수들을 적용할 수 있다. 



### 11.2.3 스파크 프로세스 조회

클러스터 프로세스들을 잘 시작했는지 확인하는 방법은 JVM 프로세스 상태도구를 사용해 프로세스를 조회하는것.

jps 명령은 다음과 같이 현재 머신에서 실행중인 JVM프로세스의 PID와 이름을 출력. 

```
$ jps
1696 CoarseGrainedExecutorBackend   ## 실행자
403 Worker                          ## 워커 프로세스
1519 SparkSubmit                    ## submit 명령이 시작한 드라이버. 
32655 Master                        ## 마스터 프로세스
6090 DriverWrapper                  ## 클러스터 내부에서 실행중인 드라이버
```



### 11.2.4 마스터 고가용성 및 복구기능

마스터 프로세스는 스파크 자체 클러스터에서 가장 중요한 컴포넌트

마스터는 클라이언트 프로세스가 애플리케이션을 제출할 수 있는 유일한 창구이며, 클라이언트를 대신해 워커에 리소스를 요청하는 역할을 담당한다. 게다가 오직 마스터로만 애플리케이션 실행 상태를 조회할 수 있다. 따라서 마스터 프로세스가 비정상적으로 종료되면 클러스터는 무용지물이 된다. 



마스터 고가용성은 마스터 프로세스가 중단되면 자동으로 재시작하는 기능. 

스파크는 마스터 프로세스를 다시 시작할 때를 대비해 마스터가 중단되기 전까지 실행중인 애플리케이션 및 워커 데이터를 복구할 수 있는 두가지 방법을 제공.

1.  파일시스템 기반 마스터 복구. 
2.  주키퍼 기반 마스터 복구 



## 11.3 스파크 자체 클러스터의 웹 UI

마스터와 워커는 프로세스를 시작하면 각 웹 UI 애플리케이션을 실행한다.

이 웹 UI는 10장의 스파크 컨텍스트의 UI와 다르다. 

스파크 자체 클러스터의 웹 UI는 마스터와 워커 정보를 보여준다. 

마스터 웹 UI 페이지는 클러스터 리소스(메모리 및 CPU 코어)사용 및 잔여 현황뿐 아니라 워커, 애플리케이션, 드라이버 정보도 제공. 

![image-20211226162752592](C:\Users\ahdbs\AppData\Roaming\Typora\typora-user-images\image-20211226162752592.png)각 워커 ID를 클릭하면 워커 프로세스가 실행한 웹 UI페이지로 이동.

이 페이지에서 해당 워커가 관리하는 실행자와 드라이버 목록을 볼수 있으며 Logs 칼럼의 각 링크를 클릭하면 해당 로그파일도 볼 수 있다. 

![image-20211226162808997](C:\Users\ahdbs\AppData\Roaming\Typora\typora-user-images\image-20211226162808997.png)

또 마스터 웹 UI페이지에서 애플리케이션 이름을 클릭하면 해당 애플리 케이션의 스파크 컨텍스트가 실행한 스파크 웹 UI페이지로 이동, 

애플리케이션 ID를 클릭하면 마스터 웹 UI의 애플리케이션 화면으로 이동. 

![image-20211226162823488](C:\Users\ahdbs\AppData\Roaming\Typora\typora-user-images\image-20211226162823488.png)

애플리 케이션 화면에서는 해당 애플리케이션을 실행중인 워커와 실행자 목록을 볼 수 있다. 

이 웹페이지는 스파크 자체 클러스터에서 발생하는 거의 모든 상황을 해결할 수 있다. 



## 11.4 스파크 자체 클러스터에서 애플리케이션 실행. 

다른 유형들과 마찬가지로 스파크 자체 클러스터에서 스파크 프로그램을 실행하는 방법에는 3가지가 있다.

- `spark-submit` 명령으로 프로그램을 제출하는 방법.
- 스파크 셸에서 프로그램을 실행하는 방법
- 별도의 애플리케이션에서 `SparkContext`객체를 초기화 및 설정하는 방법. 

어떤 방법을 사용하던 마스터 프로세스의 호스트 네임과 포트정보로 구성된 마스터 접속 URL을 지정해야 한다. 





## 11.4.1 드라이버의 위치

spark-submit 스크립트에 --deploy-mode client 인수를 지정하면 드라이버를 클리이언트에서 실행할 수 있다. 

드라이버를 클러스터 내에 실행하려면 --deploy-mod cluster 인수를 지정해 주어야 한다. 



## 11.4.2 실행가 갯수 지정 

Runing Applications 섹션에 있는 두 애플리케이션은 클러스터의 전체 12개 코어중에서 세개씩만 사용한다. 

-> SPARK_MASTER_OPTS 환경 변수에 3을 지정해서이다. 이를 제어할 수도 있고 모두 사용할 수도 있다. 

## 11.4.3 추가 클래스 패스 항목 및 파일지정

스파크를 사용하다 보면 클래스 패스를 수정하거나 추가 파일을 넣을때가 많다. 

스파크는 클래스 패스를 설정하는 여러 매개변수를 지원한다. 



### 11.4.3.1 SPARK_CLASSPATH 사용법.

SPARK_CLASSPATH 환경변수를 사용해 추가 JAR파일을 전달하는 방법. 

### 11.4.3.2 명령줄 옵션을 사용하는 방법. 

spark-submit의 --driver-class-path, --driver-library-path 명령줄 매개변수를 사용해 드라이버에 적용할 라이브러리 경로를 전달할 수 있따. 

스파크는 명령줄 옵션으로 지정된 JAR파일들은 우선 적용한다. 



### 11.4.3.3 --jars 매개변수를 사용하는 방법. 

--jars옵션에는 다양한 위치의 JAR파일을 지정할 수 있다. 

- file: 지정된 파일을 각 워커에 복사한다.  ## 일반 파일도 워커에 전송 가능. 
- local: 워커 머신 내 동일한 위치의 로컬 파일을 지정한다. 
- hdfs: HDFS 파일 경로를 지정한다. 각 워커는 HDFS에 바로 접근 할 수 있따. 
- http:, https:, ftp: 파일의 URL을 지정한다. 



### 11.4.3.4 프로그램 코드로 파일을 추가하는 방법.

SparkContext의 addJar 또는 addFile메서드를 사용해 파일을 추가할 수 있다. 



### 11.4.3.5 파이썬 파일 추가. 

spark-submit으로 파이썬 파일을 제출할 떄 --py-files 옵션을 사용해서 추가한다. 



## 11.4.4 애플리케이션 강제 종료.

spark-class 명령을 사용해 강제 종료할 수 있다. 

`spark-class org.apache.spark.deploy.Client kill <master_URL> <driver_ID>`



## 11.4.5 애플리케이션 자동재시작 

명령줄에 --.supercise옵션을 지정하면 스파크는 드라이버 프로세스에 장애가 발생하거나 비정상 종료될 때 드라이버를 재시작 한다. \



# 11.5 스파크 히스토리 서버와 이벤트 로깅. 

웹 UI에 문제가 생기고 이를 해결 하기 위해 이벤트 로깅 기능을 사용할 수 있다.

이 기능을 활성화 하면 스파크는 웹 UI를 표시하는 데 필요한 정보를 기록하고 이를 복구할 수 있다.  





# 11.6 아마존 EC2 에서 스파크 실행

이부분 직접 해봤는데 잘 안되서.. pass..



## 요약 

- 스파크 자체 클러스터는 스파크 배포판과 함께 제공되는 클러스터 매니저다. 아키텍처가 단순하고 설치 및 설정이 쉽다는 장점이 있다.
- 스파크 자체 클러스터는 마스터 프로세스와 워커 프로세스로 구성된다.
- 스파크 자체 클러스터에는 스파크 애플리케이션을 클러스터 배포 모드(드라이버를 클러스터 내에서 실행하는 모드)나 클라이언트 배포모드(드라이버를 클라이언트 JVM에서 실행하는 모드)로 실행할 수 있다.
- 스파크 자체 클러스터를 시작하려면 스파크가 제공하는 셸 스크립트를 사용하거나 각 컴포넌트를 수동으로 직접 시작해야 한다.
- 파일 시스템 마스터 복구 기능이나 주키퍼 복구 기능을 사용하면 마스터 프로세스가 비정상으로 종료되어도 자동으로 다시 시작할 수 있다.
- 스파크 자체 클러스터의 웹 UI는 클러스터에서 실행 중인 애플리케이션 정보와 유용한 클러스터의 마스터 및 워커 정보를 제공한다.
- `SPARK_CLASSPATH` 환경 변수, 명령중 옵션 및 `--jars`인수로 클래스패스 항목과 파일을 추가로 지정할 수 있다. 또는 프로그램 코드로 추가할 수도 있다.
- 스파크 히스토리 서버는 종료된 애플리케이션의 스파크 웹 UI를 제공한다. 단 히스토리 서버를 사용하려면 이벤트 로깅 기능도 같이 활성화해야 한다. 
- AMPLab에서 제공하는 spark-ec2스크립트를 사용해 아마존 EC2로 스파크 자체 클러스터를 구성할 수 있다. 

